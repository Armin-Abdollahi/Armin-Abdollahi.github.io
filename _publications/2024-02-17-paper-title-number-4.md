---
title: "Paper Title Number 3"
collection: publications
permalink: /publication/2015-10-01-paper-title-number-3
excerpt: 'This paper is about the number 3. The number 4 is left for future work.'
date: 2015-10-01
venue: 'Journal 1'
paperurl: 'http://academicpages.github.io/files/paper3.pdf'
citation: 'Your Name, You. (2015). &quot;Paper Title Number 3.&quot; <i>Journal 1</i>. 1(3).'
---

### Abstract

Bone age estimation is essential in pediatric healthcare for assessing growth and diagnosing developmental disorders. Traditional methods, such as the Greulich-Pyle atlas, are time-consuming and prone to inter-observer variability. This study proposes an automated approach using a Vision Transformer (ViT) model to improve the accuracy and efficiency of bone age prediction from hand X-ray images. The model was trained on the public Atlas dataset, which includes 1,390 left-hand X-rays of individuals aged from infancy to 18 years. To address data imbalance and enhance robustness, all images were resized to 512×512 pixels and augmented to 7,393 samples using transformations such as rotation, flipping, and brightness adjustment. The ViT model was optimized using the Adam optimizer and mean squared error (MSE) loss. It achieved a mean absolute error (MAE) of 3.2 months. Predictions within ±3 months of the actual age were considered accurate, resulting in a tolerance-based accuracy of 92%. This clinically meaningful evaluation metric reflects real-world applicability. The ViT model outperformed conventional CNN approaches, demonstrating the strength of transformer-based architectures in capturing complex spatial patterns in medical images. These results support the use of ViT as a reliable and scalable tool for automated bone age assessment in pediatric care.

<img width="7016" height="4961" alt="Certificate" src="https://github.com/user-attachments/assets/4860036d-7426-40e6-b2ae-2e9bdcb80d7f" />

![Poster](https://github.com/user-attachments/assets/f1a2690b-d376-4160-b3cc-f2e549425f5e)
